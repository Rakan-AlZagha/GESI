# GESI
 Gesture-Enabled System Interaction (GESI) 

Gesture Enabled System Interaction (GESI) is a project that enables users to interact effectively
with devices based on intuitive hand gestures. With the exception of gaming, touch and voice
have dominated the way we interact with technology over the last decade. Enabling users to
utilize gestures to operate and interact with appliances, speakers, lights, machines, and more
will allow us to develop more interactive and robust technology. The purpose of this project is to
add another dimension of user interaction with various systems and technologies. To achieve
this, I am developing a wearable piece of technology using the ESP-EYE microcontroller that
will be mounted to a pair of 3D-designed and printed glasses. The microcontroller will broadcast
raw real-time video of a user’s hand motions (first-person view) which will be intercepted by the
object-detection algorithm running remotely. Once a gesture is recognized by the deep-learning
object detection model, an API request will be sent to Amazon’s Alexa API (referred to as
“skills”) for direct device interaction. A user will be able to interact with any device connected to
their Alexa account by issuing gestures that are unique to that specific device. As the project
progresses, ultimately, the end-product will be optimized for reliable, robust, and natural
interactions with connected technologies.
